{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5901d3e5-ff3b-42b8-9d94-52cd8b908811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7f2799b-26a6-45ca-9d68-cf9fa45570ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Fisher index not specified!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m init \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sys\u001b[38;5;241m.\u001b[39margv)\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFisher index not specified!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mException\u001b[0m: Fisher index not specified!"
     ]
    }
   ],
   "source": [
    "### Compute the odd-parity CMB trispectrum of Planck 2018 data or FFP10 simulations\n",
    "# Here, we compute the contribution to the Fisher matrix from a single realization\n",
    "\n",
    "########################### IMPORTS ###########################\n",
    "import os, sys, healpy, fitsio, time, numpy as np\n",
    "sys.path.append('../')\n",
    "import polybin as pb\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "init = time.time()\n",
    "\n",
    "if len(sys.argv)!=2:\n",
    "    raise Exception(\"Fisher index not specified!\")\n",
    "index = int(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb585938-d20e-4c6b-873a-c9be2c20f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "229501a0-9c43-4f39-a993-db7b852fc727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binned lmax: 510, HEALPix lmax: 767\n"
     ]
    }
   ],
   "source": [
    "########################### SETTINGS ###########################\n",
    "\n",
    "# HEALPix settings\n",
    "Nside = 256\n",
    "lmax = 3*Nside-1\n",
    "\n",
    "# Binning parameters\n",
    "l_bins = np.load('l_bins_data.npy')\n",
    "l_bins_squeeze = l_bins.copy()\n",
    "L_bins = l_bins.copy()\n",
    "print(\"binned lmax: %d, HEALPix lmax: %d\"%(np.max(l_bins_squeeze),lmax))\n",
    "\n",
    "# Whether to include bins only partially satisfying triangle conditions\n",
    "include_partial_triangles = False\n",
    "\n",
    "# Whether to include the pixel window function\n",
    "# This should be set to True, unless we generate maps at the same realization we analyze them!\n",
    "include_pixel_window = True\n",
    "\n",
    "# whether to add a separable reduced bispectrum to the input maps\n",
    "include_synthetic_b = False\n",
    "\n",
    "# I/O\n",
    "root = '/mnt/ceph/users/ophilcox/Oliver/planck_maps/'\n",
    "outroot = '/mnt/ceph/users/ophilcox/planck_trispectrum_pol/'\n",
    "datafile = 'COM_CMB_IQU-smica_2048_R3.00_full.fits'  # Data map (from 1905.05697, 2018 SMICA map)\n",
    "\n",
    "# Beam (temperature and polarization)\n",
    "l = np.arange(lmax+1)\n",
    "beam_datT = fitsio.read(root+datafile,ext=2)['INT_BEAM']\n",
    "beam_intT = InterpolatedUnivariateSpline(np.arange(len(beam_datT)),beam_datT)\n",
    "beamT = beam_intT(l)*(l>=2)+(l<2)*1\n",
    "beam_datP = fitsio.read(root+datafile,ext=2)['POL_BEAM']\n",
    "beam_intP = InterpolatedUnivariateSpline(np.arange(len(beam_datP)),beam_datP)\n",
    "beamP = beam_intP(l)*(l>=2)+(l<2)*1\n",
    "beam = [beamT, beamP]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc821162-a150-412a-8805-6d8fdfae8791",
   "metadata": {},
   "source": [
    "# need to create $Sl$ weighting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513df0f-c2ef-4859-8ad5-f009829d2c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933d762-db0c-426b-8348-a176201a6036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class\n",
    "Sl_weighting = np.load('Sl_weighting.npy')\n",
    "assert len(Sl_weighting)==lmax+1\n",
    "base = pb.PolyBin(Nside, Sl_weighting, beam=beam, include_pixel_window=include_pixel_window)\n",
    "\n",
    "# Galactic Mask (from 1905.05697, common T map, fsky = 77.9%)\n",
    "maskfile = 'COM_Mask_CMB-common-Mask-Int_2048_R3.00.fits'\n",
    "mask_fwhm = 10. # smoothing in arcminutes\n",
    "\n",
    "# Check if output exists\n",
    "outfile = outroot+'trispectrum_fisher%d_(%d,%d,%d).npy'%(index,len(l_bins)-1,len(l_bins_squeeze)-1,len(L_bins)-1)\n",
    "\n",
    "if os.path.exists(outfile):\n",
    "    print(\"Fisher matrix already computed; exiting!\")\n",
    "    sys.exit()\n",
    "\n",
    "########################### LOAD MASK ###########################\n",
    "print(\"Loading mask\")\n",
    "mask = healpy.ud_grade(healpy.read_map(root+maskfile,field=0),Nside)\n",
    "# Convert to binary mask\n",
    "mask[mask!=1] = 0\n",
    "\n",
    "### Divide mask into small and large holes\n",
    "zero_pix = np.where(mask==0)[0] # Look at each zero point\n",
    "neighbors = healpy.get_interp_weights(Nside,zero_pix,phi=None)[0] # Identify neighbors\n",
    "neighbor_val = mask[neighbors] # Check if neighbors are zero\n",
    "neighbors[neighbor_val!=0] = -1 # Find list of particles with 0 neighbors\n",
    "cluster_id = np.arange(len(zero_pix)) # Assign ID to each point\n",
    "\n",
    "# Iterate over points (this is expensive)\n",
    "for i in range(len(zero_pix)):\n",
    "    x = np.where(neighbors==zero_pix[i])[1]\n",
    "    if len(x)==0: continue\n",
    "    cluster_id[x] = min(cluster_id[x])\n",
    "\n",
    "# Count cluster sizes + identify small clusters\n",
    "cluster_count = np.bincount(cluster_id,minlength=len(cluster_id))\n",
    "cluster_size = cluster_count[cluster_id]\n",
    "small_clusters = (cluster_size>0)&(cluster_size<20*(Nside/128)**2)\n",
    "    \n",
    "# Create inpainting mask\n",
    "inpainting_mask = 0.*mask\n",
    "inpainting_mask[zero_pix[small_clusters]]=1\n",
    "\n",
    "# Define smooth mask\n",
    "smooth_mask = healpy.smoothing(mask+inpainting_mask,mask_fwhm/60.*np.pi/180.)\n",
    "\n",
    "########################### WEIGHTING ###########################\n",
    "\n",
    "# Define S+N weighting, ensuring l<2 modes do not blow up\n",
    "Cl_filt = InterpolatedUnivariateSpline(l, Sl_weighting)(base.l_arr)   \n",
    "    \n",
    "def inpaint_map(input_map):\n",
    "    \"\"\"\n",
    "    Apply linear inpainting to a map, given an inpainting mask\n",
    "    \"\"\"\n",
    "    \n",
    "    tmp_map = input_map.copy()\n",
    "    \n",
    "    # Zero out inpainting regions \n",
    "    tmp_map[inpainting_mask==1] = 0 \n",
    "\n",
    "    # Perform iterative impainting\n",
    "    for i in range(1000):\n",
    "\n",
    "        inpaint_pix = np.where((tmp_map==0)&(inpainting_mask==1))[0]\n",
    "        if len(inpaint_pix)==0:\n",
    "            break\n",
    "        # Identify four nearest neighbors\n",
    "        neighbors = healpy.get_interp_weights(Nside,inpaint_pix)[0]\n",
    "        tmp_map[inpaint_pix] = np.mean(tmp_map[neighbors],axis=0)\n",
    "\n",
    "    return tmp_map\n",
    "\n",
    "def applySinv(input_map):\n",
    "    \"\"\"\n",
    "    Apply the quasi-optimal weighting, S^{-1} to a map. This firstly inpaints small holes in the data, applies a smooth mask, then weights by an ell-dependent factor.\n",
    "    \n",
    "    Note that this is neither diagonal nor invertible. The weighting is given by Cl_lm = B_l^2 C_l^TT + N_l here for beam B_l.\n",
    "    \"\"\"\n",
    "    ## Step 1: inpaint the data\n",
    "    tmp_map = inpaint_map(input_map)\n",
    "    \n",
    "    ## Step 2: mask out the large bad regions\n",
    "    tmp_map *= smooth_mask\n",
    "        \n",
    "    ## Step 3: Apply S+N weighting in harmonic space\n",
    "    Cinv_map = base.to_map(base.safe_divide(base.to_lm(tmp_map),Cl_filt))\n",
    "    \n",
    "    return Cinv_map\n",
    "\n",
    "########################### COMPUTE FISHER ###########################\n",
    "\n",
    "# Initialize trispectrum class\n",
    "\n",
    "tspec = pb.TSpec(base, 1.+0.*mask, applySinv, l_bins, l_bins_squeeze=l_bins_squeeze, L_bins=L_bins)\n",
    "\n",
    "# Compute Fisher contribution\n",
    "print(\"Starting Fisher matrix computation\")\n",
    "start = time.time()\n",
    "fish = tspec.compute_fisher_contribution(index,'both',verb=True)\n",
    "print(\"Computed Fisher matrix contribution after %.2f s\"%(time.time()-start))\n",
    "\n",
    "np.save(outfile,fish)\n",
    "print(\"Output saved to %s; exiting after %.2f seconds\"%(outfile,time.time()-init))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpikernel3",
   "language": "python",
   "name": "mpikernel3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
